{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\giova\\miniconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.48.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(57.95479, shape=(), dtype=float32)\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.3-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "     -------------------------------------- 10.6/10.6 MB 830.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from pandas) (1.23.1)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "     -------------------------------------- 503.5/503.5 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.3 pytz-2022.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.1-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "     ---------------------------------------- 7.4/7.4 MB 386.7 kB/s eta 0:00:00\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.0-cp39-cp39-win_amd64.whl (38.6 MB)\n",
      "     -------------------------------------- 38.6/38.6 MB 708.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.23.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=74e7ea96f024508c62e3ea6e8487876076e17ca72feb876608db7594a2564adc\n",
      "  Stored in directory: c:\\users\\giova\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-1.1.1 scipy-1.9.0 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URHPunp_MKzd"
   },
   "source": [
    "## Delvecchio Giovanni Pio mat. 0001037185\n",
    "\n",
    "###Deep Learning Exam\n",
    "\n",
    "The task consists in building a pipeline, comprehending a Neural Network using Tensorflow, which is capable of classifying a corpus of texts with respect to one between the emotions defined by Paul Ekman (Anger, Disgust, Fear, Joy, Sadness and Surprise).\n",
    "\n",
    "In order to do this, the following steps have been coded:\n",
    "- Dataset Cleaning\n",
    "- Encoding of the target classes\n",
    "- Segmentation of the sentences\n",
    "- Tokenization\n",
    "- Construction of the model\n",
    "- Training of the model\n",
    "- Plotting of the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdshWCrTOllV"
   },
   "source": [
    "### Setting up the environment for training the model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16Or1dTffz5P",
    "outputId": "d59f5f47-116a-4df9-9e10-84bb73a0ab39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0s8agcSFOwdF"
   },
   "source": [
    "## Installation of an external library for text analisys and representation\n",
    "\n",
    "source:\n",
    "https://github.com/fucaja/ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubaJ-bkshaTb",
    "outputId": "9f5faf2b-f370-43a8-cfde-02d7e7e89df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fucaja/ekphrasis.git\n",
      "  Cloning https://github.com/fucaja/ekphrasis.git to c:\\users\\giova\\appdata\\local\\temp\\pip-req-build-5pjsvm6r\n",
      "  Resolved https://github.com/fucaja/ekphrasis.git to commit 956ffd57283a63975ff49953d8ee46f8c2c385b4\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: termcolor in c:\\users\\giova\\miniconda3\\lib\\site-packages (from ekphrasis==0.5.1) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\giova\\miniconda3\\lib\\site-packages (from ekphrasis==0.5.1) (4.63.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\giova\\miniconda3\\lib\\site-packages (from ekphrasis==0.5.1) (0.4.4)\n",
      "Collecting ujson\n",
      "  Downloading ujson-5.4.0-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     -------------------------------------- 53.1/53.1 kB 911.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\giova\\miniconda3\\lib\\site-packages (from ekphrasis==0.5.1) (1.23.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from ftfy->ekphrasis==0.5.1) (0.2.5)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from matplotlib->ekphrasis==0.5.1) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from matplotlib->ekphrasis==0.5.1) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "     ------------------------------------ 944.1/944.1 kB 515.1 kB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 525.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from matplotlib->ekphrasis==0.5.1) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "     --------------------------------------- 55.4/55.4 kB 96.3 kB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     -------------------------------------- 307.0/307.0 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     -------------------------------------- 96.6/96.6 kB 459.3 kB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.7.25-cp39-cp39-win_amd64.whl (262 kB)\n",
      "     ------------------------------------ 262.8/262.8 kB 850.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->ekphrasis==0.5.1) (1.16.0)\n",
      "Building wheels for collected packages: ekphrasis\n",
      "  Building wheel for ekphrasis (setup.py): started\n",
      "  Building wheel for ekphrasis (setup.py): finished with status 'done'\n",
      "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=83390 sha256=b9f31457d7b9c8523ab2be18bece8e37a2c19d097eec01461c93398ff68365fb\n",
      "  Stored in directory: C:\\Users\\giova\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vy_7jctm\\wheels\\a2\\2e\\f3\\8e45628f6b1b7adc8421fcacd4f1eacdc15eb45200f9e5a3af\n",
      "Successfully built ekphrasis\n",
      "Installing collected packages: ujson, regex, pillow, kiwisolver, joblib, ftfy, fonttools, cycler, click, nltk, matplotlib, ekphrasis\n",
      "Successfully installed click-8.1.3 cycler-0.11.0 ekphrasis-0.5.1 fonttools-4.34.4 ftfy-6.1.1 joblib-1.1.0 kiwisolver-1.4.4 matplotlib-3.5.2 nltk-3.7 pillow-9.2.0 regex-2022.7.25 ujson-5.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/fucaja/ekphrasis.git 'C:\\Users\\giova\\AppData\\Local\\Temp\\pip-req-build-5pjsvm6r'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fucaja/ekphrasis.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDCjKu_fPGN_"
   },
   "source": [
    "## Installation of the library needed for emoji representation\n",
    "\n",
    "source:\n",
    "https://pypi.org/project/demoji/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjnyHMjsdWaa",
    "outputId": "4a7c7f94-d015-4a6a-e072-5b481a1ec268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "     --------------------------------------- 42.9/42.9 kB 99.4 kB/s eta 0:00:00\n",
      "Installing collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMJEE86jPQVg"
   },
   "source": [
    "## Installation of the library needed in order to build the model\n",
    "\n",
    "The choice has been RoBERTa base.\n",
    "This model features more parameters than BERT and, in fine tuning tasks like this one, it has shown good results at different levels of complexity of the remaining part of the network (the one that has to be trained).\n",
    "\n",
    "Sources:\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9716923\n",
    "- https://www.researchgate.net/publication/333740389_A_Comparison_of_Word-Embeddings_in_Emotion_Detection_from_Text_using_BiLSTM_CNN_and_Self-Attention#pf6\n",
    "\n",
    "In particular the best model for this task has proved to be a variation of the one proposed in the second linked paper (Polignano, Basile, Gemmis, Semeraro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCJkazXNkBb8",
    "outputId": "4e6812dc-9393-4d29-c83b-61a7395e169f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 303.4 kB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 581.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from transformers) (4.63.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.6/151.6 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from transformers) (2022.7.25)\n",
      "Requirement already satisfied: requests in c:\\users\\giova\\miniconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "     ------------------------------------ 101.5/101.5 kB 647.3 kB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Installing collected packages: tokenizers, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E98A0RMDQywG"
   },
   "source": [
    "## Installation of the library needed in order to use a self attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqCaVUsYTfw6",
    "outputId": "c25dfb58-744c-4fac-fba3-f0826f4cf7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\giova\\miniconda3\\lib\\site-packages (from keras-self-attention) (1.23.1)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=b7530c5c8d910c901eb0c75f969e6f853be7688a915db91df25f368c7dc3fd34\n",
      "  Stored in directory: c:\\users\\giova\\appdata\\local\\pip\\cache\\wheels\\78\\c1\\84\\b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.51.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4cmbi1MQ79X"
   },
   "source": [
    "## Installation of tensorflow-addons, needed to import the F1 Score supported by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suEDFR4PoG5W",
    "outputId": "47e186da-404c-4a4f-86ce-9170ce337708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.1-cp39-cp39-win_amd64.whl (758 kB)\n",
      "     ------------------------------------ 758.1/758.1 kB 214.6 kB/s eta 0:00:00\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\giova\\miniconda3\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\giova\\miniconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.17.1 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtJIIJxsRHSu"
   },
   "source": [
    "## Imports from the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IdrXtZTdQ5H",
    "outputId": "6161f002-8064-4ff1-9965-f55f41e7017c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all loaded\n"
     ]
    }
   ],
   "source": [
    "# data structures handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "import demoji\n",
    "import ekphrasis\n",
    "from demoji import replace_with_desc\n",
    "from ekphrasis.classes.spellcorrect import SpellCorrector\n",
    "from ekphrasis.classes.segmenter import Segmenter\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "#model building\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.layers import Convolution1D, MaxPooling1D, Concatenate\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "#testing \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"all loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaSHrR0mRNmH"
   },
   "source": [
    "## Loading of the dataset\n",
    "\n",
    "In order to load the dataset it's necessary to upload it on colab and run the cell, the default directory is <code>/content/</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zKD1X6VdcFV",
    "outputId": "d99d704c-d979-4ca5-cee9-cfb8348d0ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Emotion       Id\n",
      "0  My favourite food is anything I didn't have to...  neutral  eebbqej\n",
      "1  Now if he does off himself, everyone will thin...  neutral  ed00q6i\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING    anger  eezlygj\n",
      "3                        To make her feel threatened     fear  ed7ypvh\n",
      "4                             Dirty Southern Wankers    anger  ed0bdzj\n",
      "                                                Text  Emotion       Id\n",
      "0  Is this in New Orleans?? I really feel like th...  neutral  edgurhb\n",
      "1  You know the answer man, you are programmed to...      joy  ee84bjg\n",
      "2               I've never been this sad in my life!  sadness  edcu99z\n",
      "3  The economy is heavily controlled and subsidiz...      joy  edc32e2\n",
      "4  He could have easily taken a real camera from ...      joy  eepig6r\n",
      "                                                Text  Emotion       Id\n",
      "0  I’m really sorry about your situation :( Altho...  sadness  eecwqtt\n",
      "1    It's wonderful because it's awful. At not with.      joy  ed5f85d\n",
      "2  Kings fan here, good luck to you guys! Will be...      joy  een27c3\n",
      "3  I didn't know that, thank you for teaching me ...      joy  eelgwd1\n",
      "4  They got bored from haunting earth for thousan...  neutral  eem5uti\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"content/train_ekmann.csv\")\n",
    "val_set = pd.read_csv(\"content/val_ekmann.csv\")\n",
    "test_set = pd.read_csv(\"content/test_ekmann.csv\")\n",
    "\n",
    "print(train_set.head())\n",
    "print(val_set.head())\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_lttB29RilB"
   },
   "source": [
    "## Preprocessing pipeline\n",
    "\n",
    "The following cells contain all the operations performed on the corpuses in order to fit the model with appropriate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8rm-XW-dfwK",
    "outputId": "096f68e5-bd3e-46e7-d42c-6f6e806a383f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column dropped\n"
     ]
    }
   ],
   "source": [
    "#dropping column \"Id\"\n",
    "train_set = train_set.drop(\"Id\", axis = 1)\n",
    "val_set = val_set.drop(\"Id\", axis = 1)\n",
    "test_set = test_set.drop(\"Id\", axis = 1)\n",
    "\n",
    "print(\"Column dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nUty_zDdgT2",
    "outputId": "7ac45fc7-10e6-42e0-a61b-9da4a15f3c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word statistics files not found!\n",
      "Downloading... done!\n",
      "Unpacking... done!\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\miniconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't omit/backoff and unpack hashtags!\n",
      " unpack_hashtags will be set to False\n",
      "Reading english - 1grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams C:\\Users\\giova\\.ekphrasis\\stats\\english\\counts_1grams.txt\n",
      "Reading english - 2grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams C:\\Users\\giova\\.ekphrasis\\stats\\english\\counts_2grams.txt\n",
      "Training set, after preprocessing: \n",
      "['my favourite food is anything i did not have to cook myself.'\n",
      " 'now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead'\n",
      " 'why the fuck is bayless isoing' ...\n",
      " 'what are you talking about? anything bad that happened was fault only good things were doing!'\n",
      " 'more like a baptism with sexy results!' 'enjoy the ride!']\n"
     ]
    }
   ],
   "source": [
    "# here a text preprocessor from ekphrasis is built, notice that there's no tokenizer\n",
    "preprocessor = TextPreProcessor(\n",
    "  omit=['email', 'percent', 'money', 'phone', 'user', 'time', 'date', 'hashtag'],\n",
    "  unpack_contractions = True,\n",
    "  unpack_hashtags = False,\n",
    "  corrector=\"twitter\" # similar tasks of sentiment analisys were performed on twitter\n",
    "                      # so i decided to stick with this corrector\n",
    ")\n",
    "\n",
    "# encoding of the target labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(train_set[\"Emotion\"].to_numpy().reshape(-1, 1))\n",
    "num_classes = len(pd.unique(train_set[\"Emotion\"]))\n",
    "\n",
    "# instancing the segmenter from ekphrasis, training without it have also been performed\n",
    "# but the scores were lower\n",
    "segmenter = Segmenter(corpus='english')\n",
    "\n",
    "def clean_text(txt):\n",
    "  x = replace_with_desc(txt, \" \")           # change emojis with their description\n",
    "  x = x.lower()\n",
    "  x = re.sub(\"\\[[^\\]]*\\]\\s*\",'',x)          # remove text between square brackets\n",
    "  x = re.sub('http\\S*', '', x)              # remove urls\n",
    "  x = re.sub('’', '\\'', x)                  # standardize apostrophe\n",
    "  if '/r' in x:                             # check the presence of a subreddit name\n",
    "    x = re.sub('r/', '', x)\n",
    "    x = segmenter.segment(x)\n",
    "  x = re.sub(r'[^a-zA-Z\\'!?\\.]+', ' ', x)                               # remove special char, keeping only letters and '\n",
    "  x = preprocessor.pre_process_doc(x)                                   # remove eccess whitespace, unpack contraction\n",
    "  return x\n",
    "\n",
    "def preprocess(df):\n",
    "  text = df[\"Text\"]                                                     # isolate text\n",
    "  text = text.apply(clean_text).to_numpy()                              # apply text cleaning\n",
    "  classes = encoder.transform(df[\"Emotion\"].to_numpy().reshape(-1, 1))  # encode target\n",
    "  classes = classes[text.astype(bool)]                                  # remove empty strings\n",
    "  text = text[text.astype(bool)]                                        # and their respective emotions\n",
    "  return text, classes\n",
    "\n",
    "# actual preprocess call\n",
    "x_train, y_train = preprocess(train_set)\n",
    "x_val, y_val = preprocess(val_set)\n",
    "x_test, y_test = preprocess(test_set)\n",
    "\n",
    "print(\"Training set, after preprocessing: \")\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1lYdXK0UY18"
   },
   "source": [
    "## Instantiation of the RoBERTa tokenizer\n",
    "\n",
    "source: https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaTokenizer\n",
    "\n",
    "This tokenizer is derived from the GPT-2 tokenizer, given a string or a list of , it returns \n",
    "a representation of it as a pair of vectors (input_ids, attention_mask), where:\n",
    "- The input ids are token indices, numerical representations of tokens building the sequences that will be used as input by the model, the length of this vector depends on the length of the string\n",
    "- The attention masks are vectors needed to keep track of where the padding indexes are kept in the input ids, in order to keep in the model the information of the values that need to be attended to, and the padded ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "3a017673ff324c098cb8de443e1f737e",
      "e107ce3d9eea4deb8304af3bf8d46f30",
      "0b83ce2bfc2248b4bfd5d5008f5e3798",
      "75562c11dfac404585ac842f032e1132",
      "14701db9d6b3427bb8ebe22824b32015",
      "83fbf21ee5bb4ddf92ef65e72304c1b0",
      "fc675e9b1373440bb5f47b51b91836fb",
      "6747cb103985406eb74c416a75e1afeb",
      "646dc394abc749f7b207ee67f2b4a7db",
      "1fa8d859565542609b9f0bc58278acf0",
      "90be522effc14452a44d7805888cde28",
      "302f7a09bb03454480dc17f7e34d972d",
      "4f15c127cc824d1181414182f72a80b7",
      "8bfe73418e2f4088a6b2fa653250b888",
      "ae68af3115a64ef69c6c42ee0905663d",
      "f511647b607444c88ec04b2f640641d6",
      "fb631f8f43444936b56ad1112b315bf5",
      "6f5da685dfec4cf4bc7e713cf9f9d537",
      "33d4a68e7b664c0c8c4b698f3ef94a5f",
      "1204755178584881bbd4242642a21660",
      "5ab32915590447d8ad565a9b3e9884b6",
      "890bd735f19a4f3886161aae8de2c89c",
      "2eb5798f2dee44d7b530f5f4d4ccbb99",
      "13cb2386cc234d02a592ab504c42714d",
      "ccdb62aafd8c46689b217051ee95cf87",
      "37c4c8a15818497fa05c1633fa107988",
      "31df5811a663433faaf6b3b9a423fb8c",
      "8a27a25dee614db888cb07d77a241364",
      "2503142a4ef14535bfaa5fb6765028ff",
      "394c59537fcb454eb25f6b7ef7ba1077",
      "c37712ccb3b847e986ee4e877261a0c9",
      "2627f117f7094972b353aeab49537361",
      "156adb0397b548cebc1d61efa4fde401"
     ]
    },
    "id": "aBlAXu1gd1Nv",
    "outputId": "151d6d63-e562-43ea-b05b-9336b6f40929"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading vocab.json: 100%|███████████████████████████████████████████████████████| 878k/878k [00:00<00:00, 1.17MB/s]\n",
      "Downloading merges.txt: 100%|████████████████████████████████████████████████████████| 446k/446k [00:00<00:00, 798kB/s]\n",
      "Downloading config.json: 100%|█████████████████████████████████████████████████████████| 481/481 [00:00<00:00, 241kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set, after the tokenization step\n",
      "<bound method BatchEncoding.keys of {'input_ids': <tf.Tensor: shape=(43396, 211), dtype=int32, numpy=\n",
      "array([[    0,  4783,  5548, ...,     1,     1,     1],\n",
      "       [    0,  8310,   114, ...,     1,     1,     1],\n",
      "       [    0, 25800,     5, ...,     1,     1,     1],\n",
      "       ...,\n",
      "       [    0, 12196,    32, ...,     1,     1,     1],\n",
      "       [    0,  4321,   101, ...,     1,     1,     1],\n",
      "       [    0,   225, 20768, ...,     1,     1,     1]])>, 'attention_mask': <tf.Tensor: shape=(43396, 211), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>}>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", model_max_length = 211, padding_side = \"right\")\n",
    "\n",
    "x_train_list = list(x_train)#.to_numpy())\n",
    "x_val_list = list(x_val)#.to_numpy())\n",
    "x_test_list = list(x_test)#.to_numpy())\n",
    "\n",
    "encoded_train = tokenizer(x_train_list, return_tensors = \"tf\", padding = True)\n",
    "encoded_val = tokenizer(x_val_list, return_tensors = \"tf\", padding = True)\n",
    "encoded_test = tokenizer(x_test_list, return_tensors = \"tf\", padding = True)\n",
    "\n",
    "print(\"Training set, after the tokenization step\")\n",
    "print(encoded_train.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EzfuZtfUdwiO"
   },
   "outputs": [],
   "source": [
    "# Since the output of the tokenizer varies with the size of the input\n",
    "# we need to resize the validation and test set accordingly\n",
    "def resize_according_train(encoded_train, to_resize):\n",
    "  enc_t_ids = encoded_train[\"input_ids\"]\n",
    "  enc_t_att = encoded_train[\"attention_mask\"]\n",
    "  to_resize_t_ids = np.array(to_resize[\"input_ids\"])\n",
    "  to_resize_t_att = np.array(to_resize[\"attention_mask\"])\n",
    "  to_resize_new_ids = np.ones((to_resize_t_ids.shape[0], enc_t_ids.shape[1]), dtype = np.int32)\n",
    "  to_resize_new_att = np.zeros((to_resize_t_att.shape[0], enc_t_att.shape[1]), dtype = np.int32)\n",
    "  to_resize_new_ids[:to_resize_t_ids.shape[0], :to_resize_t_ids.shape[1]] = to_resize_t_ids\n",
    "  to_resize_new_att[:to_resize_t_att.shape[0], :to_resize_t_att.shape[1]] = to_resize_t_att\n",
    "  to_return = {\"input_ids\":tf.convert_to_tensor(to_resize_new_ids, dtype = np.int32), \"attention_mask\":tf.convert_to_tensor(to_resize_new_att, dtype = np.int32)}\n",
    "  return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgKU9U7tjtWD",
    "outputId": "df54fea4-20b1-432d-ddb2-cf078a101ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed resize on the encoded validation test: \n",
      "tf.Tensor(\n",
      "[[   0  354   42 ...    1    1    1]\n",
      " [   0 6968  216 ...    1    1    1]\n",
      " [   0  118   33 ...    1    1    1]\n",
      " ...\n",
      " [   0  627   94 ...    1    1    1]\n",
      " [   0  118   64 ...    1    1    1]\n",
      " [   0 4297  939 ...    1    1    1]], shape=(5425, 211), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "encoded_val = resize_according_train(encoded_train, encoded_val)\n",
    "encoded_test = resize_according_train(encoded_train, encoded_test)\n",
    "\n",
    "print(\"Performed resize on the encoded validation test: \")\n",
    "print(encoded_val[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SjW5U6CYOuM"
   },
   "source": [
    "## The model\n",
    "\n",
    "In this cell we define and compile the model in a function, in order to refresh\n",
    "weigths each time we call the function (essentially because we have a new value assigned to the pointer \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3nldgzKmOdO",
    "outputId": "06812746-0379-4210-8ef9-c6522ec65815"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tf_model.h5: 100%|██████████████████████████████████████████████████████| 627M/627M [02:33<00:00, 4.28MB/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 211)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 211)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_1[0][0]',                \n",
      " el)                            thPoolingAndCrossAt               'input_2[0][0]']                \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 211,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 211, 400)     1550400     ['tf_roberta_model[0][0]']       \n",
      "                                                                                                  \n",
      " seq_self_attention (SeqSelfAtt  (None, 211, 400)    320801      ['bidirectional[0][0]']          \n",
      " ention)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 207, 400)     800400      ['seq_self_attention[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 103, 400)     0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 103, 400)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 314, 400)     0           ['dropout_37[0][0]',             \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 400)         0           ['concatenate[0][0]']            \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          40100       ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 100)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            707         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 127,358,040\n",
      "Trainable params: 2,712,408\n",
      "Non-trainable params: 124,645,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = len(encoded_train[\"input_ids\"][0])\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    # the metrics that we want to monitor are just the loss and the F1Score, so we keep them\n",
    "    metrics=[F1Score(num_classes=7)]\n",
    "\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)                     # first layer of input of the network, input ids vectors\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)                     # second layer of input of the network, attention masks vectors\n",
    "\n",
    "    roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")              # importing the base roberta model\n",
    "    roberta_model.trainable = False                                             # RoBERTa is a large model, no reason for it to be trained again, \n",
    "                                                                                # we should perform fine tuning instead, to do so we need to set the train to False\n",
    "    x = roberta_model(ids,attention_mask=att)                                   # this will be the first layer of our complete model\n",
    "    x.trainable = False                                                         \n",
    "    bid_lstm = Bidirectional(LSTM(200, return_sequences=True))(x[0])            # first we need to add a Bi-LSTM layer, wich is used to keep track of contextual informations\n",
    "                                                                                # of the words in the sentence. \n",
    "                                                                                # The choice of 200 as a parameter is because of the fact that the task and the dataset dimensions\n",
    "                                                                                # of the paper and the one presented here, are similar. \n",
    "\n",
    "    x = SeqSelfAttention(400)(bid_lstm)                                         # The self attention layer is needed to weight the tokens with respect to the neighbouring ones\n",
    "                                                                                # according to their similarity\n",
    "\n",
    "    x = Convolution1D(400, 5)(x)                                                # Convolutional layer to capture hidden features\n",
    "    x = MaxPooling1D(2)(x)                                                      # Subsampling of the values\n",
    "    x = Dropout(0.3)(x)                                                         # Dropout in order to avoid overfitting \n",
    "    x = Concatenate(axis=1)([x, bid_lstm])                                      # Concatenation of the features extracted and the output of the LSTM, needed in order to\n",
    "                                                                                # acquire relationships between past inputs\n",
    "    x = GlobalMaxPool1D()(x)                                                    # last layers of the network, were we link our extracted features to the target classes\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(7, activation = 'softmax')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att], outputs=[x])               \n",
    "    # for classification tasks like this one (one hot encoded labels) it's necessary to use the categorical cross entropy as loss\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=metrics) \n",
    "\n",
    "\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = gpu()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJwx3rO8eDfi"
   },
   "source": [
    "## Training Function\n",
    "\n",
    "The parameters used to train the model have been chosen on the basis of various tries: \n",
    "- the number of epochs depend on how the model fits the data, thus, in order to find an appropriate value, it is possible to set epochs = 1, run the cell, inspect the results and choose to keep going on with training or stop because of overfitting (validation loss not improving and degraded performances on the validation set, while improving performances on the training set);\n",
    "- the method to chose the batch size is more theoretical: as RoBERTa should be trained on large batches, we should follow the same guideline even during fine tuning, 32 can be considered as a quite large batch, at least in this context (smaller batch sizes have been tested: 26 and 13, but the best performances were obtained with 32).\n",
    "\n",
    "It is possible to run the cell again, after the completion of a whole epoch, because <code>model</code> still references the same neural network, so running the <code>fit</code> method will result in a training step that starts from the last saved weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qPNoEjUmetX",
    "outputId": "3c7af215-3310-471a-fd43-31d6eb187ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 100/5425 [..............................] - ETA: 43:53 - loss: 1.6039 - f1_score: 0.1543"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sv \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      2\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/Ammiraglio.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m         save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# The choice of this file name is related to my Admiral Mary Read\u001b[39;00m\n\u001b[0;32m      4\u001b[0m                                                                 \u001b[38;5;66;03m# whose real name is Roberta\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoded_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoded_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "       \"/content/Ammiraglio.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='auto', save_freq='epoch') # The choice of this file name is related to my Admiral Mary Read\n",
    "                                                                # whose real name is Roberta\n",
    "\n",
    "model.fit([encoded_train[\"input_ids\"], encoded_train[\"attention_mask\"]], y_train, \n",
    "          batch_size=8, epochs=4, verbose = 1, callbacks = sv, \n",
    "          validation_data = ([encoded_val[\"input_ids\"], encoded_val[\"attention_mask\"]], y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZ4m8ohRoaew",
    "outputId": "cf5a8ee3-91ef-44fe-ff60-20074a44a7e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Saving the model, then loading it again and performing the predictions over the test set\n",
    "model.save(\"/content/Ammiraglio_model_3.h5\")\n",
    "loaded_model = tf.keras.models.load_model(\"/content/Ammiraglio_model_3.h5\", \n",
    "                                          custom_objects={\"TFRobertaModel\":TFRobertaModel.from_pretrained(\"roberta-base\"),  \n",
    "                                                          \"SeqSelfAttention\":SeqSelfAttention}, compile = False)\n",
    "obtained_preds = loaded_model.predict([encoded_test[\"input_ids\"], encoded_test[\"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iWJkv-YRQ_o"
   },
   "source": [
    "## Best fit obtained so far\n",
    "\n",
    "As shown in the papers, an F1 Macro score of 0.60 on an imbalanced dataset like this one is quite good, even tho for some applications RoBERTa shows better performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kS2Y-QKoaYc",
    "outputId": "bffc2ae9-c22f-4e23-c4f5-7cad9a73a41b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       572\n",
      "           1       0.62      0.36      0.46       116\n",
      "           2       0.64      0.68      0.66        81\n",
      "           3       0.83      0.77      0.80      1978\n",
      "           4       0.61      0.69      0.64      1648\n",
      "           5       0.64      0.49      0.56       355\n",
      "           6       0.56      0.64      0.60       677\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5427\n",
      "   macro avg       0.63      0.59      0.60      5427\n",
      "weighted avg       0.68      0.67      0.67      5427\n",
      " samples avg       0.67      0.67      0.67      5427\n",
      "\n",
      "0.6009313253656848\n"
     ]
    }
   ],
   "source": [
    "def keep_only_best_pred(obtained_preds):\n",
    "  to_return = np.zeros(obtained_preds.shape, dtype = np.int32)\n",
    "  for i in range(0, obtained_preds.shape[0]):\n",
    "    to_return[i, np.argmax(obtained_preds[i, :])] = 1\n",
    "  return to_return\n",
    "\n",
    "y_pred = keep_only_best_pred(obtained_preds)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxgNTPxvKR3J"
   },
   "source": [
    "## Try the model on a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-x-bhE6zKQiF",
    "outputId": "55dd27a9-f400-479b-cc80-3bc75274698c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computed label for: I cannot believe that this works!\n",
      "is: ['surprise']\n"
     ]
    }
   ],
   "source": [
    "str_to_process = \"I cannot believe that this works!\"\n",
    "enc_before_resizing = tokenizer([str_to_process])\n",
    "encoded_string = resize_according_train(encoded_train, enc_before_resizing)\n",
    "prediction_vector = loaded_model.predict([encoded_string[\"input_ids\"], encoded_string[\"attention_mask\"]])\n",
    "to_decode = np.zeros(prediction_vector.shape, dtype = np.int32)\n",
    "to_decode[0, np.argmax(prediction_vector)] = 1\n",
    "prediction_label = encoder.inverse_transform(to_decode)\n",
    "print(\"The computed label for: \" + str(str_to_process) + \"\\nis: \" + str(prediction_label[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSnTapOkGkK9"
   },
   "source": [
    "## Alternative, more simple fine tuning model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGAZVZgvGw_E",
    "outputId": "ec15d07d-fd7b-4b96-c832-2e12dc1c84da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 211)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 211)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_6 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_3[0][0]',                \n",
      " odel)                          thPoolingAndCrossAt               'input_4[0][0]']                \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 211,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 512)         2099200     ['tf_roberta_model_6[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 512)          0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          262656      ['dropout_262[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 512)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          131328      ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            1799        ['dropout_264[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 127,140,615\n",
      "Trainable params: 2,494,983\n",
      "Non-trainable params: 124,645,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = len(encoded_train[\"input_ids\"][0])\n",
    "\n",
    "def gpu_2():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    metrics=[F1Score(num_classes=7)]\n",
    "\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
    "    roberta_model.trainable = False\n",
    "    x = roberta_model(ids,attention_mask=att)\n",
    "    x.trainable = False\n",
    "    x = Bidirectional(LSTM(256, return_sequences=False))(x[0])                  # Bi-LSTM layer with a bigger dimension\n",
    "    x = Dropout(0.3)(x)                                                         # Dropout layer to avoid overfitting\n",
    "    x = Dense(512, activation='relu')(x)                                        # Simple dense-dropout layer pipeline\n",
    "    x = Dropout(0.3)(x)                                                         \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(7, activation = 'softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att], outputs=[x])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=metrics)\n",
    "\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = gpu_2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6OXASw1IcpG",
    "outputId": "b4e4bc61-2355-4aea-d374-b8bfdab4197c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 1.1959 - f1_score: 0.3310\n",
      "Epoch 1: val_loss improved from inf to 1.00973, saving model to /content/Ammiraglio_more_simple.h5\n",
      "1357/1357 [==============================] - 822s 594ms/step - loss: 1.1959 - f1_score: 0.3310 - val_loss: 1.0097 - val_f1_score: 0.4253\n",
      "Epoch 2/4\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 1.0256 - f1_score: 0.4389\n",
      "Epoch 2: val_loss improved from 1.00973 to 0.93473, saving model to /content/Ammiraglio_more_simple.h5\n",
      "1357/1357 [==============================] - 804s 592ms/step - loss: 1.0256 - f1_score: 0.4389 - val_loss: 0.9347 - val_f1_score: 0.5451\n",
      "Epoch 3/4\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.9619 - f1_score: 0.5171\n",
      "Epoch 3: val_loss improved from 0.93473 to 0.91024, saving model to /content/Ammiraglio_more_simple.h5\n",
      "1357/1357 [==============================] - 802s 591ms/step - loss: 0.9619 - f1_score: 0.5171 - val_loss: 0.9102 - val_f1_score: 0.5778\n",
      "Epoch 4/4\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.9138 - f1_score: 0.5557\n",
      "Epoch 4: val_loss improved from 0.91024 to 0.90222, saving model to /content/Ammiraglio_more_simple.h5\n",
      "1357/1357 [==============================] - 802s 591ms/step - loss: 0.9138 - f1_score: 0.5557 - val_loss: 0.9022 - val_f1_score: 0.5787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9940c2e4d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "       \"/content/Ammiraglio_more_simple.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "\n",
    "model.fit([encoded_train[\"input_ids\"], encoded_train[\"attention_mask\"]], y_train, \n",
    "          batch_size=32, epochs=4, verbose = 1, callbacks = sv, \n",
    "          validation_data = ([encoded_val[\"input_ids\"], encoded_val[\"attention_mask\"]], y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6m3_45YTliA",
    "outputId": "f829a995-b8e1-4552-98ad-a36ad3f0f5da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/content/Ammiraglio_model_alternative.h5\"\n",
    "model.save(save_path)\n",
    "loaded_model = tf.keras.models.load_model(save_path, \n",
    "                                          custom_objects={\"TFRobertaModel\":TFRobertaModel.from_pretrained(\"roberta-base\")}, compile = False)\n",
    "obtained_preds_more_simple = loaded_model.predict([encoded_test[\"input_ids\"], encoded_test[\"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_XcOkutKEMK",
    "outputId": "6e8ddf96-3df6-479b-cb71-e486a3cc33b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       572\n",
      "           1       0.56      0.32      0.41       116\n",
      "           2       0.61      0.63      0.62        81\n",
      "           3       0.76      0.84      0.80      1978\n",
      "           4       0.64      0.60      0.62      1648\n",
      "           5       0.56      0.51      0.53       355\n",
      "           6       0.60      0.55      0.58       677\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5427\n",
      "   macro avg       0.60      0.57      0.58      5427\n",
      "weighted avg       0.66      0.66      0.66      5427\n",
      " samples avg       0.66      0.66      0.66      5427\n",
      "\n",
      "0.5799797056939819\n"
     ]
    }
   ],
   "source": [
    "y_pred = keep_only_best_pred(obtained_preds_more_simple)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJqXUYGsi4js"
   },
   "source": [
    "## Comparison of the models\n",
    "The best model is more complex because it takes into account temporal dimensionality between sentences and spatial information between tokens, counting 2,712,408 trainable parameters.\n",
    "The second one has a larger number of units for the Bi-LSTM layer (similar scores can be obtained by sequentially add Bi-LSTM layers with a fraction of the number of units presented), but the deep features are extracted just with Dense layers, so it's less sophisticated.\n",
    "Apart from the tokenization method, the training corpus had longer sentences \n",
    "than the validation and test corpus, but even if the data was imbalanced, both networks performed quite well (0.58-0.60 F1 macro)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROBERTALSTM_059.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b83ce2bfc2248b4bfd5d5008f5e3798": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6747cb103985406eb74c416a75e1afeb",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_646dc394abc749f7b207ee67f2b4a7db",
      "value": 898823
     }
    },
    "1204755178584881bbd4242642a21660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13cb2386cc234d02a592ab504c42714d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a27a25dee614db888cb07d77a241364",
      "placeholder": "​",
      "style": "IPY_MODEL_2503142a4ef14535bfaa5fb6765028ff",
      "value": "Downloading: 100%"
     }
    },
    "14701db9d6b3427bb8ebe22824b32015": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "156adb0397b548cebc1d61efa4fde401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fa8d859565542609b9f0bc58278acf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2503142a4ef14535bfaa5fb6765028ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2627f117f7094972b353aeab49537361": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb5798f2dee44d7b530f5f4d4ccbb99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13cb2386cc234d02a592ab504c42714d",
       "IPY_MODEL_ccdb62aafd8c46689b217051ee95cf87",
       "IPY_MODEL_37c4c8a15818497fa05c1633fa107988"
      ],
      "layout": "IPY_MODEL_31df5811a663433faaf6b3b9a423fb8c"
     }
    },
    "302f7a09bb03454480dc17f7e34d972d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f15c127cc824d1181414182f72a80b7",
       "IPY_MODEL_8bfe73418e2f4088a6b2fa653250b888",
       "IPY_MODEL_ae68af3115a64ef69c6c42ee0905663d"
      ],
      "layout": "IPY_MODEL_f511647b607444c88ec04b2f640641d6"
     }
    },
    "31df5811a663433faaf6b3b9a423fb8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33d4a68e7b664c0c8c4b698f3ef94a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c4c8a15818497fa05c1633fa107988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2627f117f7094972b353aeab49537361",
      "placeholder": "​",
      "style": "IPY_MODEL_156adb0397b548cebc1d61efa4fde401",
      "value": " 481/481 [00:00&lt;00:00, 17.3kB/s]"
     }
    },
    "394c59537fcb454eb25f6b7ef7ba1077": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a017673ff324c098cb8de443e1f737e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e107ce3d9eea4deb8304af3bf8d46f30",
       "IPY_MODEL_0b83ce2bfc2248b4bfd5d5008f5e3798",
       "IPY_MODEL_75562c11dfac404585ac842f032e1132"
      ],
      "layout": "IPY_MODEL_14701db9d6b3427bb8ebe22824b32015"
     }
    },
    "4f15c127cc824d1181414182f72a80b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb631f8f43444936b56ad1112b315bf5",
      "placeholder": "​",
      "style": "IPY_MODEL_6f5da685dfec4cf4bc7e713cf9f9d537",
      "value": "Downloading: 100%"
     }
    },
    "5ab32915590447d8ad565a9b3e9884b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "646dc394abc749f7b207ee67f2b4a7db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6747cb103985406eb74c416a75e1afeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f5da685dfec4cf4bc7e713cf9f9d537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75562c11dfac404585ac842f032e1132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fa8d859565542609b9f0bc58278acf0",
      "placeholder": "​",
      "style": "IPY_MODEL_90be522effc14452a44d7805888cde28",
      "value": " 878k/878k [00:01&lt;00:00, 843kB/s]"
     }
    },
    "83fbf21ee5bb4ddf92ef65e72304c1b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890bd735f19a4f3886161aae8de2c89c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a27a25dee614db888cb07d77a241364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bfe73418e2f4088a6b2fa653250b888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33d4a68e7b664c0c8c4b698f3ef94a5f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1204755178584881bbd4242642a21660",
      "value": 456318
     }
    },
    "90be522effc14452a44d7805888cde28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae68af3115a64ef69c6c42ee0905663d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ab32915590447d8ad565a9b3e9884b6",
      "placeholder": "​",
      "style": "IPY_MODEL_890bd735f19a4f3886161aae8de2c89c",
      "value": " 446k/446k [00:00&lt;00:00, 380kB/s]"
     }
    },
    "c37712ccb3b847e986ee4e877261a0c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccdb62aafd8c46689b217051ee95cf87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_394c59537fcb454eb25f6b7ef7ba1077",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c37712ccb3b847e986ee4e877261a0c9",
      "value": 481
     }
    },
    "e107ce3d9eea4deb8304af3bf8d46f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83fbf21ee5bb4ddf92ef65e72304c1b0",
      "placeholder": "​",
      "style": "IPY_MODEL_fc675e9b1373440bb5f47b51b91836fb",
      "value": "Downloading: 100%"
     }
    },
    "f511647b607444c88ec04b2f640641d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb631f8f43444936b56ad1112b315bf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc675e9b1373440bb5f47b51b91836fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
